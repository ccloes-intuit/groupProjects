Lecture Notes, Chapter 9
CSIS-294: Intermediate Java and Introduction to Data Structures


General.  This chapter introduces us to Maps and Dictionaries and examines some of the choices existing for implementation – lists, hash tables, ordered lists.  Bearing a number of similarities to Priority Queues (chapter 8), these structures contain elements consisting of entries.

1. Entry – a key – value pair (i.e. composition), both of which can be objects.  The key will be used to retrieve its associated value.

2. Map – a collection storing entries with each key being unique.  The “association” of keys to values defines a “mapping”.


Map ADT

General.  The Map ADT is introduced on p. 369.  Notice that similar to the operations for Priority Queue, access and insertion operations utilize and/or depend on the key value.  Fig. 9.1, p. 370 shows the results of a series of operations on a map.  Similar to that as seen for a Priority Queue, notice however that the entries are not maintained in order.

List Based Implementation. As a result, its possible to use an unordered, list based implementation.  Utilizing a double linked list, this technique is only applicable to very small sample sized.  As pointed out, each of the basic operations takes O(n) time, as each requires a worst case scan through the entire list.

Hash Table Implementation.  A more efficient implementation of the Map ADT uses what is known as a Hash Table.  A Hash Table is composed of two parts: 1)a bucket array; and 2)a hash function.  This is one of the most efficient implementations for a map.  Fig. 9.2, p. 372 is a good representation of the bucket array.  Each bucket contains the entries for key-value pairs, and each bucket is identified by an integer number.  It’s somewhat misleading the way the diagram is presented, because it looks like there are multiple entries with the same key.  For example, the three entries in the bucket with an index of 3.  The reality is that while each entry has a unique key, all of the entries in a bucket have the same hash code value.

The hash function operates in two steps:

1.  Generate a hash code - map a key k to an integer value called the hash code.  The hash code can be an integer of any value.  We would like the function to minimize collisions.
2.  Convert/map hash code to bucket array index - map the hash code of #1 to an integer n in the range 0 to N-1, where N is the number of buckets in the bucket array.

Generate the hash code.  There are different algorithms available to generate the hash code.  Ideally, the approach chosen will have to account for the different types of data that might be used for a key.  Some choices are:

1. Java – the Java class Object provides the method hashCode () that can be overridden.  As we saw for the method toString (), many classes (String being one) override hashCode () in order to provide a more specific definition.  And yes, the Object version of hashCode (), doesn’t work with strings.
2. Casting – if the range of keys is less than or equal to that of an integer (when’measured’ in bits), the algorithm can perform a simple cast.  (This assumes that a cast is defined for the type of key.  In the case of Java, the key to be cast has to be one of the built-in types.  In C++, we could define a cast that would work on any type of data – i.e. we define an overloaded cast operator.)
3. Summing.  A numeric (bit based) approach is to sum the high order bits of the key with its low order bits.  Visualize a long or double key (i.e. 64 bits).  The left most 32 bits (high order) are shifted to the right 32 places, and then summed with the right most 32 bits (low order) generated by a cast of the 64 bit value to the 32 bit integer value.
4. Polynomial.  An approach more applicable to a string, is to use a polynomial hash code.  This approach takes into account the value and position of individual elements (xi’s of the text) making up a key.  As an example, this algorithm deals with the individual characters in a string.  A constant value a and its polynomial values (i.e. a, a2, a3, …) are multiplied by the xi values, generating a hash code and resulting in a low number of collisions.  ( See the authors discussion of these collisions and the choice of value as applied to a dictionary of 50,000 words for a on p. 376. )

Map hash code to bucket array index.  This mapping is performed by what is known as the compression function.  The result is an integer in the range 0 to N-1, where N is the number of buckets in the bucket array.

Goals for this algorithm are to minimize the number of collisions and to perform an associated “spreading out”  of the distribution of hashed values.  In so doing, all the buckets of the bucket array are used with a minimum number of collisions, rather than a small number of buckets being used with many, many collisions.

One compression function to accomplish this is the MAD function. Presented on p. 378 of the text, this algorithm depends on use of a prime number, and results in a fairly even spread of integer values.

Managing Collisions.  Collisions will occur.  There has to be a way to manage these.  “Separate chaining” accomplishes this by combining a list based Map with our hash table.  ( If necessary, see again section 9.1.1, p. 371 )  In this approach, each bucket entry is in fact a small list based Map.  The entries in an individual list are all the entries, each with a unique key value, that hashed to the same hash code.  Code Fragment 9.2 on p. 379 presents modified get, put, and remove operations of a Map that operate on individual bucket array elements ( the A [h(k)] of the operations. )  Figure 9.4, p. 380 is a good illustration of this.  In this simple example, remember that h(k) is defined as ‘k mod 13’, there being 13 buckets.  Do the math to verify that a key value of 54 is placed in the map of bucket number 2.


Dictionary ADT
While very similar, the difference between a Map ADT and Dictionary ADT is that a Dictionary can contain multiple entries with the same key.  ( As an example, a “real” dictionary of word definitions with multiple definitions for the same word. )  Note that the find (k) operation of p. 389 returns an ‘arbitrary’ entry in the case of multiple entries having the same key.  (Arbitrary meaning of course that it could find the first, last, or middle occurrence of entries with the same key.)

Hash table implementation.  We can use a has table to implement the Dictionary ADT nicely, if each bucket in the bucket array uses an unordered list to contain entries as opposed to the Map described in separate chaining.  Code Fragment 9.8, p. 393 shows access operations for the  Dictionary that wrap a list based hash table similar in scope to those of the Map ADT that wrapped a map based hash table.

The Search Operation.  Not one of the basic access or update operations, an efficient search is critical to implementation and use of a Dictionary.  A hash table implementation of a Dictionary ( see the previous section ) leads to good search times, but the worst case time for a search is bounded by the search time for a linked list.  And, this is of course determined by the size of the list – a size that can vary easily, growing and shrinking as necessary.   (Paradoxically, this was one of the very reasons advanced for developing a linked list – i.e. easy to grow, no waste of space).

The author mentions real time processing as an application field that needs better – i.e. a guaranteed worst case - search time, guaranteed by the fact that the structure chosen is fixed in size.  Enter the array again.  Fig. 9.7, p. 394 illustrates use of an ordered array ( i.e. ordered search table ) to maintain and order the keys of the Dictionary.  Given this organization of data, an algorithm known as the binary search algorithm can be used to search the elements of the array looking for a ‘match’.  Code Fragment 9.9, p. 395 demonstrates this algorithm.  What makes it so elegant is its use of recursion.  Each comparison (if unsuccessful) results in a halving of the search space.

Key to the analysis at the bottom of p. 396, is development of the expression n / 2i.  This value represents the number of candidate entries remaining after the ith call to BinarySearch.  When this number of candidate entries falls below 1, the implication is that there are no more candidate entries for comparison, and the search fails with no match.  In other words, we know that the search has failed when:

n/2m < 1.

Or, after reduction,

m = log n + 1

leading to the implication that binary search runs in O(log n).

See Table 9.3, p. 397 for a comparison of the big-Oh times of Dictionaries implemented with the different organizations:  1)unordered list; 2)hash table; and 3)ordered search table.

These are ten more words that may or not make

11/25/07
